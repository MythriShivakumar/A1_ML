{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_df = pd.read_csv(\"noisy_datasets/penguins.csv\")\n",
    "diamonds_df = pd.read_csv(\"noisy_datasets/diamond.csv\")\n",
    "emissions_df = pd.read_csv(\"noisy_datasets/emissions_by_country.csv\")\n",
    "\n",
    "print(\"Penguin Data \\n\", penguins_df.describe())\n",
    "print(\"\\nDiamond Data \\n\", diamonds_df.describe())\n",
    "print(\"\\nEmissions Dataset\\n\", emissions_df.describe())\n",
    "emissions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_df.info()\n",
    "penguins_df = penguins_df.dropna(subset=['species', 'island', 'gender'])\n",
    "penguins_df = penguins_df.fillna(penguins_df.select_dtypes(include='number').mean())\n",
    "penguins_df[['species', 'island', 'gender']] = penguins_df[['species', 'island', 'gender']].applymap(str.lower)\n",
    "penguins_df = penguins_df.dropna(subset=['species', 'island', 'gender'])\n",
    "penguins_df = penguins_df.fillna(penguins_df.select_dtypes(include='number').mean())\n",
    "penguins_df[['species', 'island', 'gender']] = penguins_df[['species', 'island', 'gender']].applymap(str.lower)\n",
    "Q1 = penguins_df.quantile(0.25)\n",
    "Q3 = penguins_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = (penguins_df < (Q1 - 1.5 * IQR)) | (penguins_df > (Q3 + 1.5 * IQR))\n",
    "for column in penguins_df.select_dtypes(include='number').columns:\n",
    "    penguins_df[column] = penguins_df[column].wy_y_hatatere(~outliers[column], penguins_df[column].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='gender', y='body_mass_g', data=penguins_df, estimator=np.mean, palette='muted')\n",
    "plt.title('Average Body Mass Distribution by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Body Mass (g)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='species', y='bill_length_mm', data=penguins_df, estimator=np.mean, palette='muted')\n",
    "plt.title('Average Bill Length by Species')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Average Bill Length (mm)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='species', y='calorie requirement', data=penguins_df, palette='muted')\n",
    "plt.title('Calorie Requirement Distribution by Species')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Calorie Requirement')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='island', hue='gender', data=penguins_df, palette='muted')\n",
    "plt.title('Gender Distribution by Island')\n",
    "plt.xlabel('Island')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = penguins_df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_df = pd.get_dummies(penguins_df, columns=['species', 'island'], drop_first=False)\n",
    "penguins_df['gender_target'] = penguins_df['gender'].map({'female': 0, 'male': 1})\n",
    "correlation_matrix = penguins_df.corr()\n",
    "target_correlation = correlation_matrix['gender_target']\n",
    "print(target_correlation)\n",
    "threshold = 0.1 \n",
    "low_correlation_features = target_correlation[target_correlation.abs() < threshold].index.tolist()\n",
    "print(low_correlation_features)\n",
    "corelated_df = penguins_df.drop(columns=low_correlation_features)\n",
    "corelated_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_categorical_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "min_values = corelated_df[non_categorical_columns].min()\n",
    "max_values = corelated_df[non_categorical_columns].max()\n",
    "corelated_df[non_categorical_columns] = (corelated_df[non_categorical_columns] - min_values) / (max_values - min_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corelated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logit_Regression():\n",
    "    def __init__(self, learning_rate, iterations_count, weights):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations_count = iterations_count\n",
    "        self.weights = weights\n",
    "        self.loss = []\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def cost(self, y, y_hat):\n",
    "        N = len(y)\n",
    "        return (1/N) * np.sum(-y * np.log(y_hat) - (1 - y) * np.log(1 - y_hat))\n",
    "    \n",
    "    def gradient_descent(self,X, y):\n",
    "        N = len(y)\n",
    "        self.bias = 1\n",
    "        z = np.dot(self.weights.T, X) + self.bias\n",
    "        y_hat = self.sigmoid(z)\n",
    "        delta = y_hat - y\n",
    "        x_trans = np.transpose(X)\n",
    "        dW = (x_trans*delta)/N\n",
    "        w = w - self.learning_rate*dW\n",
    "        return w, y_hat\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        best_weights = None\n",
    "        best_bias = None\n",
    "        best_acc = 0\n",
    "        for i in range(self.iterations_count):\n",
    "            self.weights, y_hat = self.gradient_descent(X,y)\n",
    "            c = self.cost(y, y_hat)\n",
    "            self.loss.append(c)\n",
    "            y_hat = self.predict(X)\n",
    "            acc = self.accuracy(y,y_hat)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_weights = self.weights\n",
    "                best_bias = self.bias\n",
    "            \n",
    "            print(f\"Iteration {i}:\\nLoss is {c}\\nAccuracy is {acc}\\n\")\n",
    "        \n",
    "        updated_weights = {'weights': best_weights, 'bias': best_bias}\n",
    "        with open('best_weights_file.pkl', 'wb') as f:\n",
    "            pickle.dump(updated_weights, f)\n",
    "        print(\"Best Accuracy during training: \", best_acc * 100)\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.bias = 1\n",
    "        weights_trans = np.transpose(self.weights)\n",
    "        z = np.dot(weights_trans, X) + self.bias\n",
    "        y_hat = self.sigmoid(z)\n",
    "        return y_hat\n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        y_hat_bin = (y_hat > 0.5).astype(int)\n",
    "        y_bin = (y > 0.5).astype(int)\n",
    "        predictions = np.sum(y_hat_bin == y_bin)\n",
    "        acc = predictions / len(y)\n",
    "        return acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corelated_df[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].values\n",
    "y = corelated_df['gender_target'].values.reshape(-1, 1) \n",
    "N = X.shape[0] \n",
    "train_size = int(0.8 * N) \n",
    "index_number = np.arange(N)\n",
    "np.random.shuffle(index_number)\n",
    "train_indices = index_number[:train_size]\n",
    "test_indices = index_number[train_size:]\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "weights = np.random.uniform(0, 1)\n",
    "learning_rate = 0.001\n",
    "iterations_count = 1000000\n",
    "model = Logit_Regression(learning_rate, iterations_count, weights)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = model.evaluate_accuracy(y_test, y_pred)\n",
    "print(f\"Test Accuracy: \",test_accuracy * 100)\n",
    "model.plot_loss()\n",
    "with open('best_model_weights.pkl', 'rb') as f:\n",
    "    saved_model = pickle.load(f)\n",
    "    print(f\"Saved Weights: \",saved_model['weights'])\n",
    "    print(f\"Saved Bias: \",saved_model['bias'])\n",
    "\n",
    "print(\"hahaha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workplease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
