{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part IV: Elastic Net Regularization using Gradient Descent\n",
    "=======================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping unrelated column \"Unnamed: 0\" since it is not required\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51334 entries, 0 to 51333\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   carat   51334 non-null  float64\n",
      " 1   table   51334 non-null  float64\n",
      " 2   price   51334 non-null  float64\n",
      " 3   x       51334 non-null  float64\n",
      " 4   y       51334 non-null  float64\n",
      " 5   z       51334 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "diamonds_df = pd.read_csv(\"diamonds_preprocessed.csv\")\n",
    "diamonds_df = diamonds_df.drop(columns='Unnamed: 0')\n",
    "print('Dropping unrelated column \\\"Unnamed: 0\\\" since it is not required')\n",
    "diamonds_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (41067, 5)\n",
      "y_train shape: (41067, 1)\n",
      "X_test shape: (10267, 5)\n",
      "y_test shape: (10267, 1)\n"
     ]
    }
   ],
   "source": [
    "X = diamonds_df[['carat', 'table', 'x', 'y', 'z']].values\n",
    "y = diamonds_df['price'].values.reshape(-1, 1) \n",
    "N = X.shape[0] \n",
    "train_size = int(0.8 * N) \n",
    "index_number = np.arange(N)\n",
    "np.random.shuffle(index_number)\n",
    "train_indices = index_number[:train_size]\n",
    "test_indices = index_number[train_size:]\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_loss(X, y, w, lambda1, lambda2):\n",
    "    N = len(y)\n",
    "    predictions = X.dot(w)\n",
    "    error = predictions - y\n",
    "    mse_loss = (1 / (2 * N)) * np.sum(error ** 2)\n",
    "    l2_penalty = (lambda1 / 2) * np.sum(w ** 2)\n",
    "    l1_penalty = lambda2 * np.sum(np.abs(w))\n",
    "    return mse_loss + l2_penalty + l1_penalty\n",
    "\n",
    "def gradient_descent(X, y, w, lambda1, lambda2, alpha, epochs, threshold=None):\n",
    "    loss_history = []\n",
    "    N, d = X.shape\n",
    "    for epoch in range(epochs):\n",
    "        predictions = X.dot(w)\n",
    "        error = predictions - y\n",
    "        gradient = (1 / N) * X.T.dot(error) + lambda1 * w + lambda2 * np.sign(w)\n",
    "        w -= alpha * gradient\n",
    "\n",
    "        loss = elastic_net_loss(X, y, w, lambda1, lambda2)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "        \n",
    "        if threshold is not None and np.all(np.abs(gradient) < threshold):\n",
    "            print(f\"Stopping early at epoch {epoch} due to small gradient: {gradient}\")\n",
    "            break\n",
    "    \n",
    "    return w, loss_history\n",
    "\n",
    "def random_initialization(input_dim, output_dim):\n",
    "    return np.random.randn(input_dim, output_dim)\n",
    "\n",
    "def zero_initialization(input_dim, output_dim):\n",
    "    return np.zeros((input_dim, output_dim))\n",
    "\n",
    "def xavier_initialization(input_dim, output_dim):\n",
    "    limit = sqrt(6 / (input_dim + output_dim))\n",
    "    return np.random.uniform(-limit, limit, size=(input_dim, output_dim))\n",
    "\n",
    "\n",
    "def three_initialization_methods(X_train, y_train, lambda1, lambda2, alpha, epochs):\n",
    "    input_dim, output_dim = X_train.shape[1], 1\n",
    "\n",
    "    w_random = random_initialization(input_dim, output_dim)\n",
    "    print(\"\\nTraining with Random Initialization:\")\n",
    "    w_random, loss_random = gradient_descent(X_train, y_train, w_random, lambda1, lambda2, alpha, epochs)\n",
    "\n",
    "    w_zero = zero_initialization(input_dim, output_dim)\n",
    "    print(\"\\nTraining with Zero Initialization:\")\n",
    "    w_zero, loss_zero = gradient_descent(X_train, y_train, w_zero, lambda1, lambda2, alpha, epochs)\n",
    "\n",
    "    w_xavier = xavier_initialization(input_dim, output_dim)\n",
    "    print(\"\\nTraining with Xavier Initialization:\")\n",
    "    w_xavier, loss_xavier = gradient_descent(X_train, y_train, w_xavier, lambda1, lambda2, alpha, epochs)\n",
    "\n",
    "    return w_random, w_zero, w_xavier\n",
    "\n",
    "def stopping_criteria_experiment(X_train, y_train, lambda1, lambda2, alpha):\n",
    "    input_dim, output_dim = X_train.shape[1], 1\n",
    "\n",
    "    w_init = random_initialization(input_dim, output_dim)\n",
    "\n",
    "    # number of iterations 10,000\n",
    "    print(\"\\nTraining with Fixed Iterations (10,000):\")\n",
    "    w_fixed_10k, loss_history_10k = gradient_descent(X_train, y_train, w_init, lambda1, lambda2, alpha, 10000)\n",
    "\n",
    "    # number of iterations 100,000\n",
    "    print(\"\\nTraining with Fixed Iterations (100,000):\")\n",
    "    w_fixed_100k, loss_history_100k = gradient_descent(X_train, y_train, w_init, lambda1, lambda2, alpha, 100000)\n",
    "\n",
    "    # Gradient Threshold (-0.01 < gradient < 0.01)\n",
    "    print(\"\\nTraining with Gradient Threshold (|grad| < 0.01):\")\n",
    "    w_grad_threshold, loss_history_threshold = gradient_descent(X_train, y_train, w_init, lambda1, lambda2, alpha, 100000, threshold=0.01)\n",
    "\n",
    "    return loss_history_10k, loss_history_100k, loss_history_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Random Initialization:\n",
      "Epoch 0, Loss: 0.9701519103153425\n",
      "Epoch 100, Loss: 0.269122967280484\n",
      "Epoch 200, Loss: 0.14060130635996956\n",
      "Epoch 300, Loss: 0.08756038960834503\n",
      "Epoch 400, Loss: 0.07214668147108969\n",
      "Epoch 500, Loss: 0.06567341316199682\n",
      "Epoch 600, Loss: 0.06172028456734572\n",
      "Epoch 700, Loss: 0.059281541629197576\n",
      "Epoch 800, Loss: 0.057636781718755956\n",
      "Epoch 900, Loss: 0.056515826603974396\n",
      "\n",
      "Training with Zero Initialization:\n",
      "Epoch 0, Loss: 0.05544253069376722\n",
      "Epoch 100, Loss: 0.05385368736381106\n",
      "Epoch 200, Loss: 0.05344217085052766\n",
      "Epoch 300, Loss: 0.053223575388244536\n",
      "Epoch 400, Loss: 0.05308423566334204\n",
      "Epoch 500, Loss: 0.052989674054975865\n",
      "Epoch 600, Loss: 0.05291919829670091\n",
      "Epoch 700, Loss: 0.052871832289486206\n",
      "Epoch 800, Loss: 0.05283123628026598\n",
      "Epoch 900, Loss: 0.05279659776830975\n",
      "\n",
      "Training with Xavier Initialization:\n",
      "Epoch 0, Loss: 0.3528053493325102\n",
      "Epoch 100, Loss: 0.23780468222264853\n",
      "Epoch 200, Loss: 0.15903355823980048\n",
      "Epoch 300, Loss: 0.10109289517004982\n",
      "Epoch 400, Loss: 0.07115899559352074\n",
      "Epoch 500, Loss: 0.061820730245946934\n",
      "Epoch 600, Loss: 0.0578412837520614\n",
      "Epoch 700, Loss: 0.05602172616070229\n",
      "Epoch 800, Loss: 0.055008631154601584\n",
      "Epoch 900, Loss: 0.054391179920522885\n"
     ]
    }
   ],
   "source": [
    "lambda1 = 0.1  # L2 regularization parameter\n",
    "lambda2 = 0.1  # L1 regularization parameter\n",
    "alpha = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "w_random, w_zero, w_xavier = three_initialization_methods(X_train, y_train, lambda1, lambda2, alpha, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Fixed Iterations (10,000):\n",
      "Epoch 0, Loss: 3.2290006488547762\n",
      "Epoch 100, Loss: 0.6180338002261506\n",
      "Epoch 200, Loss: 0.25276125561913143\n",
      "Epoch 300, Loss: 0.13836336296590707\n",
      "Epoch 400, Loss: 0.0944102421363402\n",
      "Epoch 500, Loss: 0.069604287550557\n",
      "Epoch 600, Loss: 0.06325259799169425\n",
      "Epoch 700, Loss: 0.05958992709454601\n",
      "Epoch 800, Loss: 0.05749481742411662\n",
      "Epoch 900, Loss: 0.05625333068601048\n",
      "Epoch 1000, Loss: 0.05548728250039152\n",
      "Epoch 1100, Loss: 0.054943568211906144\n",
      "Epoch 1200, Loss: 0.054502846039741336\n",
      "Epoch 1300, Loss: 0.05416522024255539\n",
      "Epoch 1400, Loss: 0.05389518171294433\n",
      "Epoch 1500, Loss: 0.053668939375495564\n",
      "Epoch 1600, Loss: 0.05348393126539243\n",
      "Epoch 1700, Loss: 0.0533391028457996\n",
      "Epoch 1800, Loss: 0.05321896762182907\n",
      "Epoch 1900, Loss: 0.053118431253688474\n",
      "Epoch 2000, Loss: 0.0530389958118355\n",
      "Epoch 2100, Loss: 0.05297723414085728\n",
      "Epoch 2200, Loss: 0.052926419344534174\n",
      "Epoch 2300, Loss: 0.05287856476093719\n",
      "Epoch 2400, Loss: 0.05286028702506324\n",
      "Epoch 2500, Loss: 0.052817115324534036\n",
      "Epoch 2600, Loss: 0.05279438188464939\n",
      "Epoch 2700, Loss: 0.05278608065802017\n",
      "Epoch 2800, Loss: 0.05277530141984228\n",
      "Epoch 2900, Loss: 0.05278113378067724\n",
      "Epoch 3000, Loss: 0.05276052666632212\n",
      "Epoch 3100, Loss: 0.052758504147138945\n",
      "Epoch 3200, Loss: 0.052770629876203484\n",
      "Epoch 3300, Loss: 0.052765916977358704\n",
      "Epoch 3400, Loss: 0.05276831932925528\n",
      "Epoch 3500, Loss: 0.05275675025608442\n",
      "Epoch 3600, Loss: 0.052771542672320385\n",
      "Epoch 3700, Loss: 0.05275844706451006\n",
      "Epoch 3800, Loss: 0.05276349189108097\n",
      "Epoch 3900, Loss: 0.05277781273790642\n",
      "Epoch 4000, Loss: 0.052772327799005384\n",
      "Epoch 4100, Loss: 0.052787202962225485\n",
      "Epoch 4200, Loss: 0.052771901423910514\n",
      "Epoch 4300, Loss: 0.05275791866925026\n",
      "Epoch 4400, Loss: 0.0527521142783932\n",
      "Epoch 4500, Loss: 0.0527600674144755\n",
      "Epoch 4600, Loss: 0.052772031629011985\n",
      "Epoch 4700, Loss: 0.05276286677975947\n",
      "Epoch 4800, Loss: 0.052767096107080386\n",
      "Epoch 4900, Loss: 0.05276242140441028\n",
      "Epoch 5000, Loss: 0.052766075762108386\n",
      "Epoch 5100, Loss: 0.0527796731402295\n",
      "Epoch 5200, Loss: 0.05277393128219372\n",
      "Epoch 5300, Loss: 0.05277807793074112\n",
      "Epoch 5400, Loss: 0.052773698025971316\n",
      "Epoch 5500, Loss: 0.05275757180199207\n",
      "Epoch 5600, Loss: 0.05275229301427597\n",
      "Epoch 5700, Loss: 0.05276490592333337\n",
      "Epoch 5800, Loss: 0.05276887761096427\n",
      "Epoch 5900, Loss: 0.05276445793418516\n",
      "Epoch 6000, Loss: 0.05276792320182514\n",
      "Epoch 6100, Loss: 0.052762661505401175\n",
      "Epoch 6200, Loss: 0.052776031685103225\n",
      "Epoch 6300, Loss: 0.0527799161126692\n",
      "Epoch 6400, Loss: 0.052765574798543644\n",
      "Epoch 6500, Loss: 0.05277894384950696\n",
      "Epoch 6600, Loss: 0.05277365853904942\n",
      "Epoch 6700, Loss: 0.05276727334669784\n",
      "Epoch 6800, Loss: 0.05275864341321933\n",
      "Epoch 6900, Loss: 0.05275649950290777\n",
      "Epoch 7000, Loss: 0.052769951156257586\n",
      "Epoch 7100, Loss: 0.052755783115647756\n",
      "Epoch 7200, Loss: 0.052778492024469575\n",
      "Epoch 7300, Loss: 0.0527630587091833\n",
      "Epoch 7400, Loss: 0.05276694857326919\n",
      "Epoch 7500, Loss: 0.05278110969535545\n",
      "Epoch 7600, Loss: 0.052766267805422644\n",
      "Epoch 7700, Loss: 0.05277963689255855\n",
      "Epoch 7800, Loss: 0.05277079950528295\n",
      "Epoch 7900, Loss: 0.05275820715223227\n",
      "Epoch 8000, Loss: 0.05276786171496997\n",
      "Epoch 8100, Loss: 0.052757062803829774\n",
      "Epoch 8200, Loss: 0.05277028900215968\n",
      "Epoch 8300, Loss: 0.05276486724695356\n",
      "Epoch 8400, Loss: 0.0527686465175083\n",
      "Epoch 8500, Loss: 0.05276434265490046\n",
      "Epoch 8600, Loss: 0.05276759030346684\n",
      "Epoch 8700, Loss: 0.05278158804930554\n",
      "Epoch 8800, Loss: 0.052776148636017386\n",
      "Epoch 8900, Loss: 0.052779753572779614\n",
      "Epoch 9000, Loss: 0.05275662404841071\n",
      "Epoch 9100, Loss: 0.052758890665176646\n",
      "Epoch 9200, Loss: 0.05276360239617703\n",
      "Epoch 9300, Loss: 0.05276725811300522\n",
      "Epoch 9400, Loss: 0.05277061081235609\n",
      "Epoch 9500, Loss: 0.05275642089167075\n",
      "Epoch 9600, Loss: 0.05276950262928358\n",
      "Epoch 9700, Loss: 0.05275580424453292\n",
      "Epoch 9800, Loss: 0.05277834231008771\n",
      "Epoch 9900, Loss: 0.052781723945484596\n",
      "\n",
      "Training with Fixed Iterations (100,000):\n",
      "Epoch 0, Loss: 0.052767112257213464\n",
      "Epoch 100, Loss: 0.052780726587845536\n",
      "Epoch 200, Loss: 0.052752440765718285\n",
      "Epoch 300, Loss: 0.052759842302530904\n",
      "Epoch 400, Loss: 0.05277292630961591\n",
      "Epoch 500, Loss: 0.052758002183506916\n",
      "Epoch 600, Loss: 0.05277161844958914\n",
      "Epoch 700, Loss: 0.052757103801890165\n",
      "Epoch 800, Loss: 0.05277032302272083\n",
      "Epoch 900, Loss: 0.052769547876955814\n",
      "Epoch 1000, Loss: 0.05276862496698119\n",
      "Epoch 1100, Loss: 0.05278305274155179\n",
      "Epoch 1200, Loss: 0.05276789236739142\n",
      "Epoch 1300, Loss: 0.052772414037229314\n",
      "Epoch 1400, Loss: 0.05275647308839674\n",
      "Epoch 1500, Loss: 0.05275955663596416\n",
      "Epoch 1600, Loss: 0.0527681150995352\n",
      "Epoch 1700, Loss: 0.052758759795436136\n",
      "Epoch 1800, Loss: 0.05276315001832779\n",
      "Epoch 1900, Loss: 0.052767148956699206\n",
      "Epoch 2000, Loss: 0.052770194766468013\n",
      "Epoch 2100, Loss: 0.0527691250087655\n",
      "Epoch 2200, Loss: 0.05276926647888228\n",
      "Epoch 2300, Loss: 0.05277361781886211\n",
      "Epoch 2400, Loss: 0.052778422432536685\n",
      "Epoch 2500, Loss: 0.05278148234605079\n",
      "Epoch 2600, Loss: 0.05274780381190393\n",
      "Epoch 2700, Loss: 0.052760502380936956\n",
      "Epoch 2800, Loss: 0.05276475631871478\n",
      "Epoch 2900, Loss: 0.05276633903844838\n",
      "Epoch 3000, Loss: 0.05277251370835588\n",
      "Epoch 3100, Loss: 0.05275793738781931\n",
      "Epoch 3200, Loss: 0.052771305132642304\n",
      "Epoch 3300, Loss: 0.052775533868114184\n",
      "Epoch 3400, Loss: 0.052765226287523656\n",
      "Epoch 3500, Loss: 0.05278365519237027\n",
      "Epoch 3600, Loss: 0.05276851979134613\n",
      "Epoch 3700, Loss: 0.05278255234755712\n",
      "Epoch 3800, Loss: 0.052748466690563475\n",
      "Epoch 3900, Loss: 0.05275261664801142\n",
      "Epoch 4000, Loss: 0.05277486385482321\n",
      "Epoch 4100, Loss: 0.0527595309910605\n",
      "Epoch 4200, Loss: 0.05277338111507448\n",
      "Epoch 4300, Loss: 0.052758555748618416\n",
      "Epoch 4400, Loss: 0.05276278138432758\n",
      "Epoch 4500, Loss: 0.05278633813797817\n",
      "Epoch 4600, Loss: 0.052770220472763515\n",
      "Epoch 4700, Loss: 0.05277453186960409\n",
      "Epoch 4800, Loss: 0.052769293318411334\n",
      "Epoch 4900, Loss: 0.052773510100552846\n",
      "Epoch 5000, Loss: 0.05275863483921935\n",
      "Epoch 5100, Loss: 0.052761311922899005\n",
      "Epoch 5200, Loss: 0.05276543508461499\n",
      "Epoch 5300, Loss: 0.052760163250854475\n",
      "Epoch 5400, Loss: 0.05276424504376859\n",
      "Epoch 5500, Loss: 0.052766924918203534\n",
      "Epoch 5600, Loss: 0.052772062759867955\n",
      "Epoch 5700, Loss: 0.05277633900025892\n",
      "Epoch 5800, Loss: 0.05277101478105528\n",
      "Epoch 5900, Loss: 0.0527749919854895\n",
      "Epoch 6000, Loss: 0.0527619191786623\n",
      "Epoch 6100, Loss: 0.05277824473227064\n",
      "Epoch 6200, Loss: 0.052760303170034176\n",
      "Epoch 6300, Loss: 0.05276226864008852\n",
      "Epoch 6400, Loss: 0.052766125339524884\n",
      "Epoch 6500, Loss: 0.05275263724558154\n",
      "Epoch 6600, Loss: 0.05277477011647648\n",
      "Epoch 6700, Loss: 0.05275975820955134\n",
      "Epoch 6800, Loss: 0.0527731643539489\n",
      "Epoch 6900, Loss: 0.05277689435489234\n",
      "Epoch 7000, Loss: 0.05276280329144889\n",
      "Epoch 7100, Loss: 0.05278605362567512\n",
      "Epoch 7200, Loss: 0.052770380331029834\n",
      "Epoch 7300, Loss: 0.052764705374493556\n",
      "Epoch 7400, Loss: 0.052768131208609126\n",
      "Epoch 7500, Loss: 0.0527537826072059\n",
      "Epoch 7600, Loss: 0.0527771106697139\n",
      "Epoch 7700, Loss: 0.05276116907700386\n",
      "Epoch 7800, Loss: 0.05276514664499758\n",
      "Epoch 7900, Loss: 0.052760376426798525\n",
      "Epoch 8000, Loss: 0.05276414662154377\n",
      "Epoch 8100, Loss: 0.05277887402182066\n",
      "Epoch 8200, Loss: 0.05277221589170506\n",
      "Epoch 8300, Loss: 0.05277597363499926\n",
      "Epoch 8400, Loss: 0.05277117205255528\n",
      "Epoch 8500, Loss: 0.052763097799101086\n",
      "Epoch 8600, Loss: 0.052760482651882316\n",
      "Epoch 8700, Loss: 0.052763304748763194\n",
      "Epoch 8800, Loss: 0.05276697026628141\n",
      "Epoch 8900, Loss: 0.05276200029608736\n",
      "Epoch 9000, Loss: 0.052765597429822196\n",
      "Epoch 9100, Loss: 0.052752973728390544\n",
      "Epoch 9200, Loss: 0.052774152909041284\n",
      "Epoch 9300, Loss: 0.05277783137637138\n",
      "Epoch 9400, Loss: 0.0527729607900297\n",
      "Epoch 9500, Loss: 0.05277655754600701\n",
      "Epoch 9600, Loss: 0.05276309831752805\n",
      "Epoch 9700, Loss: 0.052765491214394604\n",
      "Epoch 9800, Loss: 0.05276901034925372\n",
      "Epoch 9900, Loss: 0.05276075851350781\n",
      "Epoch 10000, Loss: 0.05276750489065455\n",
      "Epoch 10100, Loss: 0.052753805581737125\n",
      "Epoch 10200, Loss: 0.052767411642260065\n",
      "Epoch 10300, Loss: 0.052772842132556355\n",
      "Epoch 10400, Loss: 0.05276507295897706\n",
      "Epoch 10500, Loss: 0.052778850189465966\n",
      "Epoch 10600, Loss: 0.05276433030540889\n",
      "Epoch 10700, Loss: 0.05277878949559971\n",
      "Epoch 10800, Loss: 0.05277273105381155\n",
      "Epoch 10900, Loss: 0.05275649843670343\n",
      "Epoch 11000, Loss: 0.05277010191130066\n",
      "Epoch 11100, Loss: 0.052755299934298845\n",
      "Epoch 11200, Loss: 0.05276742732438311\n",
      "Epoch 11300, Loss: 0.05276348895051517\n",
      "Epoch 11400, Loss: 0.052766994355801386\n",
      "Epoch 11500, Loss: 0.05278112836077299\n",
      "Epoch 11600, Loss: 0.052765661444183994\n",
      "Epoch 11700, Loss: 0.052770579422638624\n",
      "Epoch 11800, Loss: 0.05277465226524636\n",
      "Epoch 11900, Loss: 0.05277797697560512\n",
      "Epoch 12000, Loss: 0.05277359582762747\n",
      "Epoch 12100, Loss: 0.052757025406328414\n",
      "Epoch 12200, Loss: 0.05276174646887177\n",
      "Epoch 12300, Loss: 0.05275859959088308\n",
      "Epoch 12400, Loss: 0.05276914065929063\n",
      "Epoch 12500, Loss: 0.05276450593912124\n",
      "Epoch 12600, Loss: 0.052767549609472414\n",
      "Epoch 12700, Loss: 0.05277219769407934\n",
      "Epoch 12800, Loss: 0.05276741650868057\n",
      "Epoch 12900, Loss: 0.05278050137455049\n",
      "Epoch 13000, Loss: 0.05276584007413481\n",
      "Epoch 13100, Loss: 0.052778883384613416\n",
      "Epoch 13200, Loss: 0.05276151393571529\n",
      "Epoch 13300, Loss: 0.05275880019744634\n",
      "Epoch 13400, Loss: 0.05277129685213644\n",
      "Epoch 13500, Loss: 0.05275659713869401\n",
      "Epoch 13600, Loss: 0.052769610849769846\n",
      "Epoch 13700, Loss: 0.052755640182438446\n",
      "Epoch 13800, Loss: 0.0527695487650152\n",
      "Epoch 13900, Loss: 0.052782713778342975\n",
      "Epoch 14000, Loss: 0.05276710804299311\n",
      "Epoch 14100, Loss: 0.05278080689745536\n",
      "Epoch 14200, Loss: 0.05276600048339195\n",
      "Epoch 14300, Loss: 0.052770579246050026\n",
      "Epoch 14400, Loss: 0.05276465895457311\n",
      "Epoch 14500, Loss: 0.05275822895694761\n",
      "Epoch 14600, Loss: 0.05277210363032391\n",
      "Epoch 14700, Loss: 0.05275698597489921\n",
      "Epoch 14800, Loss: 0.0527613747520325\n",
      "Epoch 14900, Loss: 0.05275678646153188\n",
      "Epoch 15000, Loss: 0.052768825054005555\n",
      "Epoch 15100, Loss: 0.052783381843151594\n",
      "Epoch 15200, Loss: 0.05276755337387859\n",
      "Epoch 15300, Loss: 0.05277203376498921\n",
      "Epoch 15400, Loss: 0.05276755294283068\n",
      "Epoch 15500, Loss: 0.052780267506177966\n",
      "Epoch 15600, Loss: 0.052761382661836456\n",
      "Epoch 15700, Loss: 0.05275877591360031\n",
      "Epoch 15800, Loss: 0.05276305106322814\n",
      "Epoch 15900, Loss: 0.052758441115348435\n",
      "Epoch 16000, Loss: 0.05277086480104384\n",
      "Epoch 16100, Loss: 0.05275665762443696\n",
      "Epoch 16200, Loss: 0.052769453641816004\n",
      "Epoch 16300, Loss: 0.05277369798002243\n",
      "Epoch 16400, Loss: 0.05276929107884472\n",
      "Epoch 16500, Loss: 0.052782207328953876\n",
      "Epoch 16600, Loss: 0.052767329232009955\n",
      "Epoch 16700, Loss: 0.052780718049538655\n",
      "Epoch 16800, Loss: 0.05276503096785166\n",
      "Epoch 16900, Loss: 0.05275156795776004\n",
      "Epoch 17000, Loss: 0.052764166774221605\n",
      "Epoch 17100, Loss: 0.0527582479898522\n",
      "Epoch 17200, Loss: 0.05277161030658764\n",
      "Epoch 17300, Loss: 0.05275703649468348\n",
      "Epoch 17400, Loss: 0.05276138461120407\n",
      "Epoch 17500, Loss: 0.05277502297524052\n",
      "Epoch 17600, Loss: 0.05276896614060198\n",
      "Epoch 17700, Loss: 0.05278295362348407\n",
      "Epoch 17800, Loss: 0.05276789876194958\n",
      "Epoch 17900, Loss: 0.0527720436651484\n",
      "Epoch 18000, Loss: 0.05276632412717541\n",
      "Epoch 18100, Loss: 0.052760059338998556\n",
      "Epoch 18200, Loss: 0.052771304107879904\n",
      "Epoch 18300, Loss: 0.0527587503622331\n",
      "Epoch 18400, Loss: 0.05276292257370277\n",
      "Epoch 18500, Loss: 0.05276200874765885\n",
      "Epoch 18600, Loss: 0.05277088803110752\n",
      "Epoch 18700, Loss: 0.05277522160751595\n",
      "Epoch 18800, Loss: 0.05276963223960618\n",
      "Epoch 18900, Loss: 0.05277370119392548\n",
      "Epoch 19000, Loss: 0.05276968726189887\n",
      "Epoch 19100, Loss: 0.052772457806843684\n",
      "Epoch 19200, Loss: 0.052766520232003435\n",
      "Epoch 19300, Loss: 0.05276109884142905\n",
      "Epoch 19400, Loss: 0.05276476199543856\n",
      "Epoch 19500, Loss: 0.05276065218906244\n",
      "Epoch 19600, Loss: 0.052764050599155156\n",
      "Epoch 19700, Loss: 0.052771078440137\n",
      "Epoch 19800, Loss: 0.05277160195467374\n",
      "Epoch 19900, Loss: 0.052775466161821404\n",
      "Epoch 20000, Loss: 0.052761709409895295\n",
      "Epoch 20100, Loss: 0.0527747385894145\n",
      "Epoch 20200, Loss: 0.05276957429541502\n",
      "Epoch 20300, Loss: 0.05277698928104665\n",
      "Epoch 20400, Loss: 0.05276680323484396\n",
      "Epoch 20500, Loss: 0.052752736362748805\n",
      "Epoch 20600, Loss: 0.05276598677856385\n",
      "Epoch 20700, Loss: 0.05276036313205904\n",
      "Epoch 20800, Loss: 0.052774096330490475\n",
      "Epoch 20900, Loss: 0.05277771204497017\n",
      "Epoch 21000, Loss: 0.05276289308221738\n",
      "Epoch 21100, Loss: 0.0527768632949108\n",
      "Epoch 21200, Loss: 0.05276600548583607\n",
      "Epoch 21300, Loss: 0.05277518765752838\n",
      "Epoch 21400, Loss: 0.052770137901100425\n",
      "Epoch 21500, Loss: 0.052763603840019865\n",
      "Epoch 21600, Loss: 0.05276806321477659\n",
      "Epoch 21700, Loss: 0.052753504060825816\n",
      "Epoch 21800, Loss: 0.052766325019733405\n",
      "Epoch 21900, Loss: 0.05276103980219609\n",
      "Epoch 22000, Loss: 0.05276450693788092\n",
      "Epoch 22100, Loss: 0.05277919886227181\n",
      "Epoch 22200, Loss: 0.05276377068750139\n",
      "Epoch 22300, Loss: 0.05277714416477475\n",
      "Epoch 22400, Loss: 0.05277188549506305\n",
      "Epoch 22500, Loss: 0.05277555389105216\n",
      "Epoch 22600, Loss: 0.05276216085819935\n",
      "Epoch 22700, Loss: 0.052757832723907494\n",
      "Epoch 22800, Loss: 0.05276841274731262\n",
      "Epoch 22900, Loss: 0.05276298631400038\n",
      "Epoch 23000, Loss: 0.052766386523020736\n",
      "Epoch 23100, Loss: 0.052752853157776274\n",
      "Epoch 23200, Loss: 0.05276570031777101\n",
      "Epoch 23300, Loss: 0.05277714415836874\n",
      "Epoch 23400, Loss: 0.05277415891802055\n",
      "Epoch 23500, Loss: 0.052777428717649205\n",
      "Epoch 23600, Loss: 0.05276298436350147\n",
      "Epoch 23700, Loss: 0.052776404996265985\n",
      "Epoch 23800, Loss: 0.052771249252611424\n",
      "Epoch 23900, Loss: 0.05275563506457577\n",
      "Epoch 24000, Loss: 0.05276863699880509\n",
      "Epoch 24100, Loss: 0.052754297649402274\n",
      "Epoch 24200, Loss: 0.05276773189737571\n",
      "Epoch 24300, Loss: 0.05275357345802988\n",
      "Epoch 24400, Loss: 0.05276611637705923\n",
      "Epoch 24500, Loss: 0.05277968729254808\n",
      "Epoch 24600, Loss: 0.05276465535321251\n",
      "Epoch 24700, Loss: 0.052778994761896125\n",
      "Epoch 24800, Loss: 0.0527642945993496\n",
      "Epoch 24900, Loss: 0.052777268177697075\n",
      "Epoch 25000, Loss: 0.052788640809691\n",
      "Epoch 25100, Loss: 0.05275599370479574\n",
      "Epoch 25200, Loss: 0.052762537626501654\n",
      "Epoch 25300, Loss: 0.05275507896068071\n",
      "Epoch 25400, Loss: 0.052767978001440924\n",
      "Epoch 25500, Loss: 0.05276328873250877\n",
      "Epoch 25600, Loss: 0.05276652159928943\n",
      "Epoch 25700, Loss: 0.05277104715813884\n",
      "Epoch 25800, Loss: 0.052765731947982404\n",
      "Epoch 25900, Loss: 0.052770030658160584\n",
      "Epoch 26000, Loss: 0.05277456613495141\n",
      "Epoch 26100, Loss: 0.05277753189887997\n",
      "Epoch 26200, Loss: 0.05277980392080028\n",
      "Epoch 26300, Loss: 0.05275709703664108\n",
      "Epoch 26400, Loss: 0.05276127350973327\n",
      "Epoch 26500, Loss: 0.05276215502675502\n",
      "Epoch 26600, Loss: 0.05276849725117689\n",
      "Epoch 26700, Loss: 0.05275448746945247\n",
      "Epoch 26800, Loss: 0.0527676645177331\n",
      "Epoch 26900, Loss: 0.05277179976861243\n",
      "Epoch 27000, Loss: 0.05276646805093245\n",
      "Epoch 27100, Loss: 0.05277960244325375\n",
      "Epoch 27200, Loss: 0.05276502642900616\n",
      "Epoch 27300, Loss: 0.05277870719025339\n",
      "Epoch 27400, Loss: 0.05277514644081551\n",
      "Epoch 27500, Loss: 0.05275758629586275\n",
      "Epoch 27600, Loss: 0.052770841429268335\n",
      "Epoch 27700, Loss: 0.052755901512099065\n",
      "Epoch 27800, Loss: 0.052769523143823036\n",
      "Epoch 27900, Loss: 0.05276478600074346\n",
      "Epoch 28000, Loss: 0.05275939389345301\n",
      "Epoch 28100, Loss: 0.05278203462432142\n",
      "Epoch 28200, Loss: 0.05276639508315226\n",
      "Epoch 28300, Loss: 0.052770789641634536\n",
      "Epoch 28400, Loss: 0.05276592449332169\n",
      "Epoch 28500, Loss: 0.05276995564792812\n",
      "Epoch 28600, Loss: 0.05277788228799935\n",
      "Epoch 28700, Loss: 0.05275765676117976\n",
      "Epoch 28800, Loss: 0.05276179710322526\n",
      "Epoch 28900, Loss: 0.05275695301327568\n",
      "Epoch 29000, Loss: 0.052760865086807295\n",
      "Epoch 29100, Loss: 0.05277603686049686\n",
      "Epoch 29200, Loss: 0.05276845396458218\n",
      "Epoch 29300, Loss: 0.05277254393297221\n",
      "Epoch 29400, Loss: 0.0527674897746889\n",
      "Epoch 29500, Loss: 0.052771255202550604\n",
      "Epoch 29600, Loss: 0.052766716776996535\n",
      "Epoch 29700, Loss: 0.052779654777250856\n",
      "Epoch 29800, Loss: 0.05276691425598677\n",
      "Epoch 29900, Loss: 0.05275867021240112\n",
      "Epoch 30000, Loss: 0.05276230682643419\n",
      "Epoch 30100, Loss: 0.052752027330652\n",
      "Epoch 30200, Loss: 0.05277035326179062\n",
      "Epoch 30300, Loss: 0.0527743014751484\n",
      "Epoch 30400, Loss: 0.05276926976199081\n",
      "Epoch 30500, Loss: 0.05277303866075948\n",
      "Epoch 30600, Loss: 0.05275936265814686\n",
      "Epoch 30700, Loss: 0.052781885322341494\n",
      "Epoch 30800, Loss: 0.052766956541386335\n",
      "Epoch 30900, Loss: 0.052770944687467014\n",
      "Epoch 31000, Loss: 0.052764490156405774\n",
      "Epoch 31100, Loss: 0.052750687562446746\n",
      "Epoch 31200, Loss: 0.05277298038680008\n",
      "Epoch 31300, Loss: 0.052757889859594426\n",
      "Epoch 31400, Loss: 0.05276169131883444\n",
      "Epoch 31500, Loss: 0.052775373319544974\n",
      "Epoch 31600, Loss: 0.052760759162455574\n",
      "Epoch 31700, Loss: 0.05278452826468096\n",
      "Epoch 31800, Loss: 0.052768564440859804\n",
      "Epoch 31900, Loss: 0.05277220911642869\n",
      "Epoch 32000, Loss: 0.05277476252167643\n",
      "Epoch 32100, Loss: 0.052771363078184384\n",
      "Epoch 32200, Loss: 0.052760378297769486\n",
      "Epoch 32300, Loss: 0.05275961146283525\n",
      "Epoch 32400, Loss: 0.05276326361309403\n",
      "Epoch 32500, Loss: 0.05275858903614633\n",
      "Epoch 32600, Loss: 0.05276205702419863\n",
      "Epoch 32700, Loss: 0.052767126859981445\n",
      "Epoch 32800, Loss: 0.05277032692063487\n",
      "Epoch 32900, Loss: 0.052774126456593795\n",
      "Epoch 33000, Loss: 0.05276959554189697\n",
      "Epoch 33100, Loss: 0.052773031792070706\n",
      "Epoch 33200, Loss: 0.05277093990236573\n",
      "Epoch 33300, Loss: 0.052780679744626885\n",
      "Epoch 33400, Loss: 0.0527652816386194\n",
      "Epoch 33500, Loss: 0.05275678881731943\n",
      "Epoch 33600, Loss: 0.05276401317849289\n",
      "Epoch 33700, Loss: 0.052750647424886686\n",
      "Epoch 33800, Loss: 0.05277282976508198\n",
      "Epoch 33900, Loss: 0.05277642745500772\n",
      "Epoch 34000, Loss: 0.05276168757576265\n",
      "Epoch 34100, Loss: 0.05277499567337831\n",
      "Epoch 34200, Loss: 0.05276097040840341\n",
      "Epoch 34300, Loss: 0.052782955072364274\n",
      "Epoch 34400, Loss: 0.05278809794878038\n",
      "Epoch 34500, Loss: 0.05276729342753194\n",
      "Epoch 34600, Loss: 0.052766311421484996\n",
      "Epoch 34700, Loss: 0.052752106626956584\n",
      "Epoch 34800, Loss: 0.052763185316812795\n",
      "Epoch 34900, Loss: 0.05275982742426801\n",
      "Epoch 35000, Loss: 0.05276334918093986\n",
      "Epoch 35100, Loss: 0.0527772183017577\n",
      "Epoch 35200, Loss: 0.05276226870269932\n",
      "Epoch 35300, Loss: 0.052767133024052185\n",
      "Epoch 35400, Loss: 0.0527708765466577\n",
      "Epoch 35500, Loss: 0.05277420212664797\n",
      "Epoch 35600, Loss: 0.052788895151216014\n",
      "Epoch 35700, Loss: 0.052764888809129655\n",
      "Epoch 35800, Loss: 0.0527580915955339\n",
      "Epoch 35900, Loss: 0.052761972683392964\n",
      "Epoch 36000, Loss: 0.0527654572289642\n",
      "Epoch 36100, Loss: 0.052761073999405946\n",
      "Epoch 36200, Loss: 0.052764093163799125\n",
      "Epoch 36300, Loss: 0.05276866064720737\n",
      "Epoch 36400, Loss: 0.05277311869985757\n",
      "Epoch 36500, Loss: 0.052776445204698035\n",
      "Epoch 36600, Loss: 0.052762322510152074\n",
      "Epoch 36700, Loss: 0.05277521300705053\n",
      "Epoch 36800, Loss: 0.0527798000280706\n",
      "Epoch 36900, Loss: 0.052755636297074325\n",
      "Epoch 37000, Loss: 0.05276759658056761\n",
      "Epoch 37100, Loss: 0.052753278177621744\n",
      "Epoch 37200, Loss: 0.05276610928834121\n",
      "Epoch 37300, Loss: 0.05276321402230403\n",
      "Epoch 37400, Loss: 0.052766108394243366\n",
      "Epoch 37500, Loss: 0.052778386430535874\n",
      "Epoch 37600, Loss: 0.05276360108747767\n",
      "Epoch 37700, Loss: 0.05277714363036097\n",
      "Epoch 37800, Loss: 0.05276265957337331\n",
      "Epoch 37900, Loss: 0.05276728622174109\n",
      "Epoch 38000, Loss: 0.05279030671937658\n",
      "Epoch 38100, Loss: 0.052754812405370326\n",
      "Epoch 38200, Loss: 0.05276833751109168\n",
      "Epoch 38300, Loss: 0.052753831095288424\n",
      "Epoch 38400, Loss: 0.05275808954993154\n",
      "Epoch 38500, Loss: 0.052776198668513685\n",
      "Epoch 38600, Loss: 0.05276535716910108\n",
      "Epoch 38700, Loss: 0.05277955462487455\n",
      "Epoch 38800, Loss: 0.05276420008990977\n",
      "Epoch 38900, Loss: 0.052768511078893604\n",
      "Epoch 39000, Loss: 0.05276437142396949\n",
      "Epoch 39100, Loss: 0.05277633556660777\n",
      "Epoch 39200, Loss: 0.05278085534679778\n",
      "Epoch 39300, Loss: 0.0527555261071144\n",
      "Epoch 39400, Loss: 0.05275967207513636\n",
      "Epoch 39500, Loss: 0.05275537920719791\n",
      "Epoch 39600, Loss: 0.052767366520960014\n",
      "Epoch 39700, Loss: 0.05277159112332111\n",
      "Epoch 39800, Loss: 0.05276590930957296\n",
      "Epoch 39900, Loss: 0.05277022084515797\n",
      "Epoch 40000, Loss: 0.05276595290161841\n",
      "Epoch 40100, Loss: 0.0527783610580442\n",
      "Epoch 40200, Loss: 0.05276387996993663\n",
      "Epoch 40300, Loss: 0.0527770215589349\n",
      "Epoch 40400, Loss: 0.05278116077751675\n",
      "Epoch 40500, Loss: 0.052748211411455956\n",
      "Epoch 40600, Loss: 0.05276968132963769\n",
      "Epoch 40700, Loss: 0.052754901540673735\n",
      "Epoch 40800, Loss: 0.05276807965424776\n",
      "Epoch 40900, Loss: 0.05277196355269713\n",
      "Epoch 41000, Loss: 0.05275807802809022\n",
      "Epoch 41100, Loss: 0.05277488444229425\n",
      "Epoch 41200, Loss: 0.05276537519639202\n",
      "Epoch 41300, Loss: 0.05277917678745338\n",
      "Epoch 41400, Loss: 0.05277424861670113\n",
      "Epoch 41500, Loss: 0.05276864425597168\n",
      "Epoch 41600, Loss: 0.05277554075686434\n",
      "Epoch 41700, Loss: 0.05275653641036801\n",
      "Epoch 41800, Loss: 0.05276778827085232\n",
      "Epoch 41900, Loss: 0.052755342332715005\n",
      "Epoch 42000, Loss: 0.05275937373760703\n",
      "Epoch 42100, Loss: 0.052773537942004456\n",
      "Epoch 42200, Loss: 0.052767075716485236\n",
      "Epoch 42300, Loss: 0.05277111553148216\n",
      "Epoch 42400, Loss: 0.05276599057355148\n",
      "Epoch 42500, Loss: 0.052769934093090415\n",
      "Epoch 42600, Loss: 0.052777654460747725\n",
      "Epoch 42700, Loss: 0.052778575229899705\n",
      "Epoch 42800, Loss: 0.05277116419715444\n",
      "Epoch 42900, Loss: 0.052757283690174635\n",
      "Epoch 43000, Loss: 0.05276106536947277\n",
      "Epoch 43100, Loss: 0.05275624612350478\n",
      "Epoch 43200, Loss: 0.052767766462247234\n",
      "Epoch 43300, Loss: 0.05277336591599388\n",
      "Epoch 43400, Loss: 0.05276802310669229\n",
      "Epoch 43500, Loss: 0.052771834936588075\n",
      "Epoch 43600, Loss: 0.05275823896005222\n",
      "Epoch 43700, Loss: 0.052771296916917926\n",
      "Epoch 43800, Loss: 0.05278469430548001\n",
      "Epoch 43900, Loss: 0.05277957943385994\n",
      "Epoch 44000, Loss: 0.05276735398823695\n",
      "Epoch 44100, Loss: 0.05274957169486926\n",
      "Epoch 44200, Loss: 0.052762469433182906\n",
      "Epoch 44300, Loss: 0.05275674541723238\n",
      "Epoch 44400, Loss: 0.05277001536057582\n",
      "Epoch 44500, Loss: 0.05277364058642962\n",
      "Epoch 44600, Loss: 0.05275940847533435\n",
      "Epoch 44700, Loss: 0.05277347271587958\n",
      "Epoch 44800, Loss: 0.05276771456059297\n",
      "Epoch 44900, Loss: 0.052771360568493894\n",
      "Epoch 45000, Loss: 0.052785167539252824\n",
      "Epoch 45100, Loss: 0.05277023571070919\n",
      "Epoch 45200, Loss: 0.05276442004659724\n",
      "Epoch 45300, Loss: 0.05275861570037899\n",
      "Epoch 45400, Loss: 0.05276225928324607\n",
      "Epoch 45500, Loss: 0.052763682237163045\n",
      "Epoch 45600, Loss: 0.05276083272560543\n",
      "Epoch 45700, Loss: 0.052775494031979044\n",
      "Epoch 45800, Loss: 0.052760443839387564\n",
      "Epoch 45900, Loss: 0.05277309660332625\n",
      "Epoch 46000, Loss: 0.052768253979565555\n",
      "Epoch 46100, Loss: 0.05277171455320795\n",
      "Epoch 46200, Loss: 0.05277676235080594\n",
      "Epoch 46300, Loss: 0.0527716187797997\n",
      "Epoch 46400, Loss: 0.052764548201742215\n",
      "Epoch 46500, Loss: 0.05275949083027938\n",
      "Epoch 46600, Loss: 0.052762799248015246\n",
      "Epoch 46700, Loss: 0.052761094749621415\n",
      "Epoch 46800, Loss: 0.05276235698391187\n",
      "Epoch 46900, Loss: 0.05277539861936903\n",
      "Epoch 47000, Loss: 0.05277038583073419\n",
      "Epoch 47100, Loss: 0.05277363264287381\n",
      "Epoch 47200, Loss: 0.05275988582986283\n",
      "Epoch 47300, Loss: 0.0527731207636581\n",
      "Epoch 47400, Loss: 0.05278680703159759\n",
      "Epoch 47500, Loss: 0.05277121287901873\n",
      "Epoch 47600, Loss: 0.05276483018390888\n",
      "Epoch 47700, Loss: 0.05275091642922794\n",
      "Epoch 47800, Loss: 0.05276414757785644\n",
      "Epoch 47900, Loss: 0.05276845274768691\n",
      "Epoch 48000, Loss: 0.05276246166221654\n",
      "Epoch 48100, Loss: 0.05277582585514858\n",
      "Epoch 48200, Loss: 0.052761094491466376\n",
      "Epoch 48300, Loss: 0.052775201189630284\n",
      "Epoch 48400, Loss: 0.05276094019446589\n",
      "Epoch 48500, Loss: 0.052773411159084065\n",
      "Epoch 48600, Loss: 0.05278739276926763\n",
      "Epoch 48700, Loss: 0.05276786053765193\n",
      "Epoch 48800, Loss: 0.05275819437837563\n",
      "Epoch 48900, Loss: 0.05275204938197041\n",
      "Epoch 49000, Loss: 0.05276440720470793\n",
      "Epoch 49100, Loss: 0.05277832834921858\n",
      "Epoch 49200, Loss: 0.05276278878931147\n",
      "Epoch 49300, Loss: 0.05276734061303706\n",
      "Epoch 49400, Loss: 0.05276221238986777\n",
      "Epoch 49500, Loss: 0.05277518382708937\n",
      "Epoch 49600, Loss: 0.05277066056639962\n",
      "Epoch 49700, Loss: 0.05277376506117983\n",
      "Epoch 49800, Loss: 0.0527781348167647\n",
      "Epoch 49900, Loss: 0.05276252542644798\n",
      "Epoch 50000, Loss: 0.052762362033605424\n",
      "Epoch 50100, Loss: 0.05275926150877565\n",
      "Epoch 50200, Loss: 0.05276453885169634\n",
      "Epoch 50300, Loss: 0.052769059132698685\n",
      "Epoch 50400, Loss: 0.05276397497635861\n",
      "Epoch 50500, Loss: 0.052768018885248416\n",
      "Epoch 50600, Loss: 0.05276257674706547\n",
      "Epoch 50700, Loss: 0.052775557560278116\n",
      "Epoch 50800, Loss: 0.052773004548690446\n",
      "Epoch 50900, Loss: 0.05277480785841138\n",
      "Epoch 51000, Loss: 0.05277900733422651\n",
      "Epoch 51100, Loss: 0.05275572172029898\n",
      "Epoch 51200, Loss: 0.05276687464481769\n",
      "Epoch 51300, Loss: 0.05275254718993656\n",
      "Epoch 51400, Loss: 0.05276602355944756\n",
      "Epoch 51500, Loss: 0.052769786668510954\n",
      "Epoch 51600, Loss: 0.05276417886424576\n",
      "Epoch 51700, Loss: 0.05277794493741782\n",
      "Epoch 51800, Loss: 0.05276294446913793\n",
      "Epoch 51900, Loss: 0.05276716913403039\n",
      "Epoch 52000, Loss: 0.05278092396626396\n",
      "Epoch 52100, Loss: 0.052774220083083044\n",
      "Epoch 52200, Loss: 0.05278985527173756\n",
      "Epoch 52300, Loss: 0.0527543663694365\n",
      "Epoch 52400, Loss: 0.05275839979111934\n",
      "Epoch 52500, Loss: 0.052753558540089764\n",
      "Epoch 52600, Loss: 0.05275734825557269\n",
      "Epoch 52700, Loss: 0.05278049684769838\n",
      "Epoch 52800, Loss: 0.05276463335270508\n",
      "Epoch 52900, Loss: 0.052768737827987404\n",
      "Epoch 53000, Loss: 0.052764036027273156\n",
      "Epoch 53100, Loss: 0.05276779432203853\n",
      "Epoch 53200, Loss: 0.05278152956594043\n",
      "Epoch 53300, Loss: 0.0527756432614591\n",
      "Epoch 53400, Loss: 0.05277958888930069\n",
      "Epoch 53500, Loss: 0.052755262735046715\n",
      "Epoch 53600, Loss: 0.05275886003942731\n",
      "Epoch 53700, Loss: 0.0527540542481337\n",
      "Epoch 53800, Loss: 0.05276670243622409\n",
      "Epoch 53900, Loss: 0.05277080052466369\n",
      "Epoch 54000, Loss: 0.052766013455911476\n",
      "Epoch 54100, Loss: 0.05276962185311601\n",
      "Epoch 54200, Loss: 0.052764753289601375\n",
      "Epoch 54300, Loss: 0.0527780459314722\n",
      "Epoch 54400, Loss: 0.05278189533775649\n",
      "Epoch 54500, Loss: 0.05276749022846766\n",
      "Epoch 54600, Loss: 0.052779416829984896\n",
      "Epoch 54700, Loss: 0.05274758503195044\n",
      "Epoch 54800, Loss: 0.052769199878610756\n",
      "Epoch 54900, Loss: 0.052764118039845785\n",
      "Epoch 55000, Loss: 0.0527582402162103\n",
      "Epoch 55100, Loss: 0.05277169770982357\n",
      "Epoch 55200, Loss: 0.052757432127400715\n",
      "Epoch 55300, Loss: 0.05278046046785184\n",
      "Epoch 55400, Loss: 0.052765005851167834\n",
      "Epoch 55500, Loss: 0.052768778049954654\n",
      "Epoch 55600, Loss: 0.05278275138095981\n",
      "Epoch 55700, Loss: 0.05276792824270607\n",
      "Epoch 55800, Loss: 0.05277120677371177\n",
      "Epoch 55900, Loss: 0.05275627918454233\n",
      "Epoch 56000, Loss: 0.052759880404858725\n",
      "Epoch 56100, Loss: 0.05277384131350564\n",
      "Epoch 56200, Loss: 0.052758802076992926\n",
      "Epoch 56300, Loss: 0.05277242848375657\n",
      "Epoch 56400, Loss: 0.05276670019302042\n",
      "Epoch 56500, Loss: 0.05277038347626021\n",
      "Epoch 56600, Loss: 0.05276620868633741\n",
      "Epoch 56700, Loss: 0.05276955940240261\n",
      "Epoch 56800, Loss: 0.0527745670438931\n",
      "Epoch 56900, Loss: 0.05277829097424842\n",
      "Epoch 57000, Loss: 0.05276933096718251\n",
      "Epoch 57100, Loss: 0.05275050355511404\n",
      "Epoch 57200, Loss: 0.05276064022528105\n",
      "Epoch 57300, Loss: 0.05276536941496358\n",
      "Epoch 57400, Loss: 0.052768976969534656\n",
      "Epoch 57500, Loss: 0.052772574132522836\n",
      "Epoch 57600, Loss: 0.052758405834109325\n",
      "Epoch 57700, Loss: 0.05277144310025834\n",
      "Epoch 57800, Loss: 0.052757835941194674\n",
      "Epoch 57900, Loss: 0.05278055644709833\n",
      "Epoch 58000, Loss: 0.05278397646359979\n",
      "Epoch 58100, Loss: 0.05276906078822015\n",
      "Epoch 58200, Loss: 0.05276502980540173\n",
      "Epoch 58300, Loss: 0.05274893976670861\n",
      "Epoch 58400, Loss: 0.05276769208866659\n",
      "Epoch 58500, Loss: 0.05277488184222006\n",
      "Epoch 58600, Loss: 0.05275986888490423\n",
      "Epoch 58700, Loss: 0.052773592259384064\n",
      "Epoch 58800, Loss: 0.05275890664888693\n",
      "Epoch 58900, Loss: 0.05276437797610283\n",
      "Epoch 59000, Loss: 0.05277356045181822\n",
      "Epoch 59100, Loss: 0.0527703327999826\n",
      "Epoch 59200, Loss: 0.05278477584342235\n",
      "Epoch 59300, Loss: 0.05276970835827099\n",
      "Epoch 59400, Loss: 0.05275477747842127\n",
      "Epoch 59500, Loss: 0.05275833323962445\n",
      "Epoch 59600, Loss: 0.05276147716398764\n",
      "Epoch 59700, Loss: 0.05277569971690962\n",
      "Epoch 59800, Loss: 0.05276026760261127\n",
      "Epoch 59900, Loss: 0.052764933956886785\n",
      "Epoch 60000, Loss: 0.05276901435528709\n",
      "Epoch 60100, Loss: 0.052772120776546805\n",
      "Epoch 60200, Loss: 0.052774027886685254\n",
      "Epoch 60300, Loss: 0.05277109779408632\n",
      "Epoch 60400, Loss: 0.05277560740892387\n",
      "Epoch 60500, Loss: 0.05278058439103005\n",
      "Epoch 60600, Loss: 0.05276342952443214\n",
      "Epoch 60700, Loss: 0.052749678180331855\n",
      "Epoch 60800, Loss: 0.05276230378094149\n",
      "Epoch 60900, Loss: 0.052766517302465586\n",
      "Epoch 61000, Loss: 0.052767417492892085\n",
      "Epoch 61100, Loss: 0.052774128787685885\n",
      "Epoch 61200, Loss: 0.052759756076003896\n",
      "Epoch 61300, Loss: 0.052773159070664315\n",
      "Epoch 61400, Loss: 0.05277753627411375\n",
      "Epoch 61500, Loss: 0.052763575556064146\n",
      "Epoch 61600, Loss: 0.05278593970450582\n",
      "Epoch 61700, Loss: 0.05277065984283309\n",
      "Epoch 61800, Loss: 0.05276432823201483\n",
      "Epoch 61900, Loss: 0.052750216278125824\n",
      "Epoch 62000, Loss: 0.052754414161210364\n",
      "Epoch 62100, Loss: 0.052776870347497916\n",
      "Epoch 62200, Loss: 0.052761274692203666\n",
      "Epoch 62300, Loss: 0.05277520698087754\n",
      "Epoch 62400, Loss: 0.05276047825925795\n",
      "Epoch 62500, Loss: 0.05276473208140624\n",
      "Epoch 62600, Loss: 0.05278868592233161\n",
      "Epoch 62700, Loss: 0.05277218666685572\n",
      "Epoch 62800, Loss: 0.052776688185660836\n",
      "Epoch 62900, Loss: 0.05276841990243688\n",
      "Epoch 63000, Loss: 0.0527558491195808\n",
      "Epoch 63100, Loss: 0.05276055172585033\n",
      "Epoch 63200, Loss: 0.05276338562525285\n",
      "Epoch 63300, Loss: 0.05276758645934134\n",
      "Epoch 63400, Loss: 0.05276218265738332\n",
      "Epoch 63500, Loss: 0.0527663083773634\n",
      "Epoch 63600, Loss: 0.05276243702291639\n",
      "Epoch 63700, Loss: 0.05277426489278356\n",
      "Epoch 63800, Loss: 0.05277863737194901\n",
      "Epoch 63900, Loss: 0.05277336527214264\n",
      "Epoch 64000, Loss: 0.05277725428348304\n",
      "Epoch 64100, Loss: 0.05274898300325448\n",
      "Epoch 64200, Loss: 0.05276559151485604\n",
      "Epoch 64300, Loss: 0.052763106787123384\n",
      "Epoch 64400, Loss: 0.05276430762260092\n",
      "Epoch 64500, Loss: 0.05276809639712419\n",
      "Epoch 64600, Loss: 0.052754603671482714\n",
      "Epoch 64700, Loss: 0.052776972657897506\n",
      "Epoch 64800, Loss: 0.05276189528909115\n",
      "Epoch 64900, Loss: 0.05277540632079745\n",
      "Epoch 65000, Loss: 0.052779184004083116\n",
      "Epoch 65100, Loss: 0.05276506002444661\n",
      "Epoch 65200, Loss: 0.052788436327499876\n",
      "Epoch 65300, Loss: 0.0527549196957831\n",
      "Epoch 65400, Loss: 0.0527644179393142\n",
      "Epoch 65500, Loss: 0.05277024362773857\n",
      "Epoch 65600, Loss: 0.05275580070568117\n",
      "Epoch 65700, Loss: 0.052769963500616385\n",
      "Epoch 65800, Loss: 0.05276339659347029\n",
      "Epoch 65900, Loss: 0.05276725913021696\n",
      "Epoch 66000, Loss: 0.05276238164025822\n",
      "Epoch 66100, Loss: 0.05276622802949585\n",
      "Epoch 66200, Loss: 0.0527810699917892\n",
      "Epoch 66300, Loss: 0.05277461476781862\n",
      "Epoch 66400, Loss: 0.05277849758947236\n",
      "Epoch 66500, Loss: 0.05275372492100119\n",
      "Epoch 66600, Loss: 0.05275738200759419\n",
      "Epoch 66700, Loss: 0.05276837758838608\n",
      "Epoch 66800, Loss: 0.052765529607514086\n",
      "Epoch 66900, Loss: 0.05276925690940111\n",
      "Epoch 67000, Loss: 0.05276418851635143\n",
      "Epoch 67100, Loss: 0.052767948362738244\n",
      "Epoch 67200, Loss: 0.05275497080747318\n",
      "Epoch 67300, Loss: 0.05277685630887774\n",
      "Epoch 67400, Loss: 0.052780447060902035\n",
      "Epoch 67500, Loss: 0.05277556856609817\n",
      "Epoch 67600, Loss: 0.05277907736557956\n",
      "Epoch 67700, Loss: 0.05274632475699884\n",
      "Epoch 67800, Loss: 0.052760945305680304\n",
      "Epoch 67900, Loss: 0.05277141370186901\n",
      "Epoch 68000, Loss: 0.05276646253763578\n",
      "Epoch 68100, Loss: 0.0527699587385156\n",
      "Epoch 68200, Loss: 0.05275607246003795\n",
      "Epoch 68300, Loss: 0.052769641611281864\n",
      "Epoch 68400, Loss: 0.0527736674479093\n",
      "Epoch 68500, Loss: 0.05276749426808839\n",
      "Epoch 68600, Loss: 0.052781108671159385\n",
      "Epoch 68700, Loss: 0.05276664288380428\n",
      "Epoch 68800, Loss: 0.05277690574266024\n",
      "Epoch 68900, Loss: 0.05275518735749138\n",
      "Epoch 69000, Loss: 0.05275872025053\n",
      "Epoch 69100, Loss: 0.05277216737319494\n",
      "Epoch 69200, Loss: 0.05275739193493836\n",
      "Epoch 69300, Loss: 0.0527717161270776\n",
      "Epoch 69400, Loss: 0.05276573638328903\n",
      "Epoch 69500, Loss: 0.05276928536618887\n",
      "Epoch 69600, Loss: 0.052783438225255046\n",
      "Epoch 69700, Loss: 0.05276812704719146\n",
      "Epoch 69800, Loss: 0.052773023110041326\n",
      "Epoch 69900, Loss: 0.05277211220772536\n",
      "Epoch 70000, Loss: 0.05277359736175528\n",
      "Epoch 70100, Loss: 0.0527560232849893\n",
      "Epoch 70200, Loss: 0.05275923858758993\n",
      "Epoch 70300, Loss: 0.052763982152681646\n",
      "Epoch 70400, Loss: 0.052759025244844854\n",
      "Epoch 70500, Loss: 0.05277145278649868\n",
      "Epoch 70600, Loss: 0.052766665533443814\n",
      "Epoch 70700, Loss: 0.05276985635134016\n",
      "Epoch 70800, Loss: 0.052774543102774164\n",
      "Epoch 70900, Loss: 0.05276952062221438\n",
      "Epoch 71000, Loss: 0.052782403832252536\n",
      "Epoch 71100, Loss: 0.05276791063717244\n",
      "Epoch 71200, Loss: 0.05276983321868729\n",
      "Epoch 71300, Loss: 0.052747650913416065\n",
      "Epoch 71400, Loss: 0.05276075024813939\n",
      "Epoch 71500, Loss: 0.05277359029292314\n",
      "Epoch 71600, Loss: 0.05275880577495971\n",
      "Epoch 71700, Loss: 0.05277187413070521\n",
      "Epoch 71800, Loss: 0.05275782786207246\n",
      "Epoch 71900, Loss: 0.05277179103607156\n",
      "Epoch 72000, Loss: 0.0527835057420035\n",
      "Epoch 72100, Loss: 0.05276959710500271\n",
      "Epoch 72200, Loss: 0.05278332912501108\n",
      "Epoch 72300, Loss: 0.05276852864403729\n",
      "Epoch 72400, Loss: 0.05275378950048752\n",
      "Epoch 72500, Loss: 0.05275318240540308\n",
      "Epoch 72600, Loss: 0.05276061440784944\n",
      "Epoch 72700, Loss: 0.05277441273091003\n",
      "Epoch 72800, Loss: 0.05275926857872818\n",
      "Epoch 72900, Loss: 0.05276367468601179\n",
      "Epoch 73000, Loss: 0.05275883363040212\n",
      "Epoch 73100, Loss: 0.05277108969733348\n",
      "Epoch 73200, Loss: 0.05278571798960415\n",
      "Epoch 73300, Loss: 0.05276997437475178\n",
      "Epoch 73400, Loss: 0.05277444437522402\n",
      "Epoch 73500, Loss: 0.05276979591486641\n",
      "Epoch 73600, Loss: 0.05276255347267607\n",
      "Epoch 73700, Loss: 0.052768251316744626\n",
      "Epoch 73800, Loss: 0.05276087327954889\n",
      "Epoch 73900, Loss: 0.052765201781425776\n",
      "Epoch 74000, Loss: 0.05276035438591492\n",
      "Epoch 74100, Loss: 0.05277323429649767\n",
      "Epoch 74200, Loss: 0.05275896875961535\n",
      "Epoch 74300, Loss: 0.05277179442226827\n",
      "Epoch 74400, Loss: 0.05277598014809037\n",
      "Epoch 74500, Loss: 0.052771382366288686\n",
      "Epoch 74600, Loss: 0.05277535093076756\n",
      "Epoch 74700, Loss: 0.05276978460897433\n",
      "Epoch 74800, Loss: 0.052763116709992036\n",
      "Epoch 74900, Loss: 0.052767282956974915\n",
      "Epoch 75000, Loss: 0.0527624945635808\n",
      "Epoch 75100, Loss: 0.05276618966798226\n",
      "Epoch 75200, Loss: 0.05276063342882725\n",
      "Epoch 75300, Loss: 0.05277403559154143\n",
      "Epoch 75400, Loss: 0.0527594948018234\n",
      "Epoch 75500, Loss: 0.05276353502685383\n",
      "Epoch 75600, Loss: 0.05277710487477537\n",
      "Epoch 75700, Loss: 0.05277127906305394\n",
      "Epoch 75800, Loss: 0.052785282601142416\n",
      "Epoch 75900, Loss: 0.05277018071002926\n",
      "Epoch 76000, Loss: 0.05275466116107799\n",
      "Epoch 76100, Loss: 0.05276825136538148\n",
      "Epoch 76200, Loss: 0.05276219328661771\n",
      "Epoch 76300, Loss: 0.05277624494899838\n",
      "Epoch 76400, Loss: 0.05276075566397592\n",
      "Epoch 76500, Loss: 0.05276501607523773\n",
      "Epoch 76600, Loss: 0.052765608937935984\n",
      "Epoch 76700, Loss: 0.05276731877389433\n",
      "Epoch 76800, Loss: 0.05277757441761476\n",
      "Epoch 76900, Loss: 0.05277181628947393\n",
      "Epoch 77000, Loss: 0.05277593827960755\n",
      "Epoch 77100, Loss: 0.05276346846744352\n",
      "Epoch 77200, Loss: 0.05275548793486776\n",
      "Epoch 77300, Loss: 0.052768596466956356\n",
      "Epoch 77400, Loss: 0.052762883792596305\n",
      "Epoch 77500, Loss: 0.05276673091639327\n",
      "Epoch 77600, Loss: 0.052762413663545255\n",
      "Epoch 77700, Loss: 0.052766000900045074\n",
      "Epoch 77800, Loss: 0.05277248832746436\n",
      "Epoch 77900, Loss: 0.05277378505557004\n",
      "Epoch 78000, Loss: 0.052777735338027654\n",
      "Epoch 78100, Loss: 0.05276385140213564\n",
      "Epoch 78200, Loss: 0.05277684125223949\n",
      "Epoch 78300, Loss: 0.052756723154306094\n",
      "Epoch 78400, Loss: 0.05276510033891541\n",
      "Epoch 78500, Loss: 0.05276872326853206\n",
      "Epoch 78600, Loss: 0.05275464614140053\n",
      "Epoch 78700, Loss: 0.05276769864190076\n",
      "Epoch 78800, Loss: 0.05276054154677706\n",
      "Epoch 78900, Loss: 0.05277627611281715\n",
      "Epoch 79000, Loss: 0.052779904073308015\n",
      "Epoch 79100, Loss: 0.0527649720682208\n",
      "Epoch 79200, Loss: 0.05277886537702059\n",
      "Epoch 79300, Loss: 0.05276450280938504\n",
      "Epoch 79400, Loss: 0.05277755260716259\n",
      "Epoch 79500, Loss: 0.0527542866615219\n",
      "Epoch 79600, Loss: 0.05275607811218689\n",
      "Epoch 79700, Loss: 0.05276986927322514\n",
      "Epoch 79800, Loss: 0.052755316681996796\n",
      "Epoch 79900, Loss: 0.05276839366978957\n",
      "Epoch 80000, Loss: 0.05276308599540306\n",
      "Epoch 80100, Loss: 0.05276664771303803\n",
      "Epoch 80200, Loss: 0.05278129357740089\n",
      "Epoch 80300, Loss: 0.05276581029725967\n",
      "Epoch 80400, Loss: 0.052779427945885984\n",
      "Epoch 80500, Loss: 0.0527741040540185\n",
      "Epoch 80600, Loss: 0.05277771746367293\n",
      "Epoch 80700, Loss: 0.052745110753115075\n",
      "Epoch 80800, Loss: 0.05275717188513068\n",
      "Epoch 80900, Loss: 0.052769373440132814\n",
      "Epoch 81000, Loss: 0.05276508660409099\n",
      "Epoch 81100, Loss: 0.0527684852334663\n",
      "Epoch 81200, Loss: 0.052754749278246714\n",
      "Epoch 81300, Loss: 0.052767457686287766\n",
      "Epoch 81400, Loss: 0.05277205562936403\n",
      "Epoch 81500, Loss: 0.05277615353823442\n",
      "Epoch 81600, Loss: 0.05277966876582681\n",
      "Epoch 81700, Loss: 0.052765283796962784\n",
      "Epoch 81800, Loss: 0.052778684424315575\n",
      "Epoch 81900, Loss: 0.05275644080133114\n",
      "Epoch 82000, Loss: 0.052763753453584195\n",
      "Epoch 82100, Loss: 0.052770794472387694\n",
      "Epoch 82200, Loss: 0.05275642655371872\n",
      "Epoch 82300, Loss: 0.052769938587693514\n",
      "Epoch 82400, Loss: 0.05275571137131471\n",
      "Epoch 82500, Loss: 0.052768534886994276\n",
      "Epoch 82600, Loss: 0.052782098191615834\n",
      "Epoch 82700, Loss: 0.052766895953980895\n",
      "Epoch 82800, Loss: 0.05278135955983374\n",
      "Epoch 82900, Loss: 0.05276661690849902\n",
      "Epoch 83000, Loss: 0.05277419095059964\n",
      "Epoch 83100, Loss: 0.05277132003952472\n",
      "Epoch 83200, Loss: 0.05275808865462778\n",
      "Epoch 83300, Loss: 0.052772368689136394\n",
      "Epoch 83400, Loss: 0.052757167432016534\n",
      "Epoch 83500, Loss: 0.052761519425660666\n",
      "Epoch 83600, Loss: 0.052765533159056216\n",
      "Epoch 83700, Loss: 0.05276852185336365\n",
      "Epoch 83800, Loss: 0.052773085310140924\n",
      "Epoch 83900, Loss: 0.05276777563589319\n",
      "Epoch 84000, Loss: 0.0527721317971063\n",
      "Epoch 84100, Loss: 0.05277688355374056\n",
      "Epoch 84200, Loss: 0.05277324646655457\n",
      "Epoch 84300, Loss: 0.052764431408206386\n",
      "Epoch 84400, Loss: 0.05275897876355963\n",
      "Epoch 84500, Loss: 0.05276320490596961\n",
      "Epoch 84600, Loss: 0.052767676093313835\n",
      "Epoch 84700, Loss: 0.05277064141395859\n",
      "Epoch 84800, Loss: 0.052756523800496655\n",
      "Epoch 84900, Loss: 0.05276956475007266\n",
      "Epoch 85000, Loss: 0.05277382370065371\n",
      "Epoch 85100, Loss: 0.052768774004187634\n",
      "Epoch 85200, Loss: 0.052781952827753005\n",
      "Epoch 85300, Loss: 0.05276726823308234\n",
      "Epoch 85400, Loss: 0.05276828924045063\n",
      "Epoch 85500, Loss: 0.05276500081465128\n",
      "Epoch 85600, Loss: 0.05275133562995199\n",
      "Epoch 85700, Loss: 0.052773006154498515\n",
      "Epoch 85800, Loss: 0.05275793314691125\n",
      "Epoch 85900, Loss: 0.052771599278961856\n",
      "Epoch 86000, Loss: 0.052767379589604035\n",
      "Epoch 86100, Loss: 0.05276141907641311\n",
      "Epoch 86200, Loss: 0.052784681309456086\n",
      "Epoch 86300, Loss: 0.052768976725626277\n",
      "Epoch 86400, Loss: 0.052773162859312876\n",
      "Epoch 86500, Loss: 0.052768065816601\n",
      "Epoch 86600, Loss: 0.05275373117668897\n",
      "Epoch 86700, Loss: 0.05277580652915417\n",
      "Epoch 86800, Loss: 0.05275985359051745\n",
      "Epoch 86900, Loss: 0.05276398481836658\n",
      "Epoch 87000, Loss: 0.052758982426506014\n",
      "Epoch 87100, Loss: 0.0527627735244813\n",
      "Epoch 87200, Loss: 0.052778388775953686\n",
      "Epoch 87300, Loss: 0.05277052550328141\n",
      "Epoch 87400, Loss: 0.052774716311150854\n",
      "Epoch 87500, Loss: 0.05276971900566474\n",
      "Epoch 87600, Loss: 0.05277355151354257\n",
      "Epoch 87700, Loss: 0.052760791378727946\n",
      "Epoch 87800, Loss: 0.05276211600216538\n",
      "Epoch 87900, Loss: 0.05276584395234341\n",
      "Epoch 88000, Loss: 0.05276068727748969\n",
      "Epoch 88100, Loss: 0.05276431786788445\n",
      "Epoch 88200, Loss: 0.05275126537244703\n",
      "Epoch 88300, Loss: 0.05277290510316941\n",
      "Epoch 88400, Loss: 0.05277699346896664\n",
      "Epoch 88500, Loss: 0.05277170257743425\n",
      "Epoch 88600, Loss: 0.052775345522862525\n",
      "Epoch 88700, Loss: 0.05276166486927634\n",
      "Epoch 88800, Loss: 0.0527844717681919\n",
      "Epoch 88900, Loss: 0.05276925634488604\n",
      "Epoch 89000, Loss: 0.052758777639635684\n",
      "Epoch 89100, Loss: 0.05276647297118476\n",
      "Epoch 89200, Loss: 0.05275262294993963\n",
      "Epoch 89300, Loss: 0.05277543093655554\n",
      "Epoch 89400, Loss: 0.05276002668484314\n",
      "Epoch 89500, Loss: 0.052763839125797775\n",
      "Epoch 89600, Loss: 0.05277757711613423\n",
      "Epoch 89700, Loss: 0.05276290961276984\n",
      "Epoch 89800, Loss: 0.05277926021066031\n",
      "Epoch 89900, Loss: 0.05277090003544045\n",
      "Epoch 90000, Loss: 0.052774602614860854\n",
      "Epoch 90100, Loss: 0.05277283960956258\n",
      "Epoch 90200, Loss: 0.05275411037674811\n",
      "Epoch 90300, Loss: 0.05276411762251224\n",
      "Epoch 90400, Loss: 0.05276197803635218\n",
      "Epoch 90500, Loss: 0.052765618594836985\n",
      "Epoch 90600, Loss: 0.05276079842107259\n",
      "Epoch 90700, Loss: 0.05276423870914575\n",
      "Epoch 90800, Loss: 0.052769399548559456\n",
      "Epoch 90900, Loss: 0.05277309789810707\n",
      "Epoch 91000, Loss: 0.05277684300285446\n",
      "Epoch 91100, Loss: 0.05277195537426483\n",
      "Epoch 91200, Loss: 0.052775323467655705\n",
      "Epoch 91300, Loss: 0.05276263843978041\n",
      "Epoch 91400, Loss: 0.05276422608091492\n",
      "Epoch 91500, Loss: 0.052767699529509604\n",
      "Epoch 91600, Loss: 0.052762968725747844\n",
      "Epoch 91700, Loss: 0.05276622700779922\n",
      "Epoch 91800, Loss: 0.052752877400357\n",
      "Epoch 91900, Loss: 0.052774661110070904\n",
      "Epoch 92000, Loss: 0.052778915151649376\n",
      "Epoch 92100, Loss: 0.05276404289728456\n",
      "Epoch 92200, Loss: 0.05277730540680505\n",
      "Epoch 92300, Loss: 0.05276331069551706\n",
      "Epoch 92400, Loss: 0.052777310454968675\n",
      "Epoch 92500, Loss: 0.052775195445527785\n",
      "Epoch 92600, Loss: 0.05275534580091519\n",
      "Epoch 92700, Loss: 0.05276851008740768\n",
      "Epoch 92800, Loss: 0.05275419306268999\n",
      "Epoch 92900, Loss: 0.052768138200452126\n",
      "Epoch 93000, Loss: 0.05276199605864601\n",
      "Epoch 93100, Loss: 0.05276542935851754\n",
      "Epoch 93200, Loss: 0.0527793992897964\n",
      "Epoch 93300, Loss: 0.052764452589781394\n",
      "Epoch 93400, Loss: 0.05276918741583847\n",
      "Epoch 93500, Loss: 0.05277318996072046\n",
      "Epoch 93600, Loss: 0.052776553775898585\n",
      "Epoch 93700, Loss: 0.052771616758437764\n",
      "Epoch 93800, Loss: 0.05275560596686565\n",
      "Epoch 93900, Loss: 0.05276013733324876\n",
      "Epoch 94000, Loss: 0.05276417847573607\n",
      "Epoch 94100, Loss: 0.05276751853397461\n",
      "Epoch 94200, Loss: 0.05276316118380086\n",
      "Epoch 94300, Loss: 0.05276611402601551\n",
      "Epoch 94400, Loss: 0.052770683921465986\n",
      "Epoch 94500, Loss: 0.05276615588455629\n",
      "Epoch 94600, Loss: 0.05277861070963766\n",
      "Epoch 94700, Loss: 0.05276451573743323\n",
      "Epoch 94800, Loss: 0.052777316010014716\n",
      "Epoch 94900, Loss: 0.05276205634370418\n",
      "Epoch 95000, Loss: 0.052757357861484507\n",
      "Epoch 95100, Loss: 0.05276963779973273\n",
      "Epoch 95200, Loss: 0.052755266005863506\n",
      "Epoch 95300, Loss: 0.05276811147783252\n",
      "Epoch 95400, Loss: 0.05276555692206276\n",
      "Epoch 95500, Loss: 0.052768059076674464\n",
      "Epoch 95600, Loss: 0.05278077689287901\n",
      "Epoch 95700, Loss: 0.05276584571769556\n",
      "Epoch 95800, Loss: 0.05277934087469345\n",
      "Epoch 95900, Loss: 0.052764790240536846\n",
      "Epoch 96000, Loss: 0.05276943978145997\n",
      "Epoch 96100, Loss: 0.05277208883695105\n",
      "Epoch 96200, Loss: 0.052756754230096\n",
      "Epoch 96300, Loss: 0.05277031441823964\n",
      "Epoch 96400, Loss: 0.05275578474362208\n",
      "Epoch 96500, Loss: 0.052760070506621154\n",
      "Epoch 96600, Loss: 0.052772089751917856\n",
      "Epoch 96700, Loss: 0.052767398386794756\n",
      "Epoch 96800, Loss: 0.052781658675175695\n",
      "Epoch 96900, Loss: 0.052766236019759466\n",
      "Epoch 97000, Loss: 0.05277061425059494\n",
      "Epoch 97100, Loss: 0.05276626554365236\n",
      "Epoch 97200, Loss: 0.052778574187441855\n",
      "Epoch 97300, Loss: 0.05276861248132749\n",
      "Epoch 97400, Loss: 0.05275749734037395\n",
      "Epoch 97500, Loss: 0.052761707661327484\n",
      "Epoch 97600, Loss: 0.0527572192443174\n",
      "Epoch 97700, Loss: 0.052769480774634114\n",
      "Epoch 97800, Loss: 0.052773667558367904\n",
      "Epoch 97900, Loss: 0.052767883987844655\n",
      "Epoch 98000, Loss: 0.052772234585478466\n",
      "Epoch 98100, Loss: 0.05276786161759544\n",
      "Epoch 98200, Loss: 0.052780650470448366\n",
      "Epoch 98300, Loss: 0.05276610726270267\n",
      "Epoch 98400, Loss: 0.05277595049464698\n",
      "Epoch 98500, Loss: 0.05276339346604634\n",
      "Epoch 98600, Loss: 0.05275900704498489\n",
      "Epoch 98700, Loss: 0.05276905833684561\n",
      "Epoch 98800, Loss: 0.052756848937681705\n",
      "Epoch 98900, Loss: 0.052770083050427415\n",
      "Epoch 99000, Loss: 0.052774022163822217\n",
      "Epoch 99100, Loss: 0.052760025727531405\n",
      "Epoch 99200, Loss: 0.05277337262893554\n",
      "Epoch 99300, Loss: 0.052767434823936914\n",
      "Epoch 99400, Loss: 0.05278125821376006\n",
      "Epoch 99500, Loss: 0.052774179957909347\n",
      "Epoch 99600, Loss: 0.052760254637610825\n",
      "Epoch 99700, Loss: 0.052764599371179166\n",
      "Epoch 99800, Loss: 0.05275857570609831\n",
      "Epoch 99900, Loss: 0.05277233235891455\n",
      "\n",
      "Training with Gradient Threshold (|grad| < 0.01):\n",
      "Epoch 0, Loss: 0.05275730225274781\n",
      "Stopping early at epoch 0 due to small gradient: [[ 0.00971848]\n",
      " [ 0.00893369]\n",
      " [ 0.00468462]\n",
      " [ 0.00427863]\n",
      " [-0.00014999]]\n"
     ]
    }
   ],
   "source": [
    "loss_history_10k, loss_history_100k, loss_history_threshold = stopping_criteria_experiment(X_train, y_train, lambda1, lambda2, alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
